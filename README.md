# Программа транскрибации речи (Speech Recognition)

Программа для автоматического распознавания речи из аудиофайлов с использованием **Vosk** или **Whisper** (выбор через конфигурацию).

## Возможности

- ✅ **Два движка распознавания:** Vosk (быстрый) и Whisper (точный)
- ✅ **Переключение через конфигурацию** - сравните качество обоих движков
- ✅ Поддержка множества аудиоформатов (WAV, MP3, OGG, FLAC, M4A, WMA, AAC, WebM)
- ✅ Автоматическая конвертация в нужный формат (для Vosk) или прямая обработка (для Whisper)
- ✅ Пакетная обработка файлов из директории
- ✅ Сохранение результатов в формате Markdown
- ✅ Автоматическое определение языка (Vosk из названия модели, Whisper автоматически)
- ✅ Автоматическое перемещение обработанных файлов в `.data/processed`
- ✅ Чистый вывод транскрипции без лишней информации

## Требования

- Python 3.7 или выше
- ffmpeg (устанавливается отдельно, см. [инструкцию ниже](#3-установка-ffmpeg)) - **нужен только для Vosk**
- **Для Vosk:** скачанная модель для нужного языка
- **Для Whisper:** модель скачается автоматически при первом запуске

**Примечание:** `ffmpeg` нужен только при использовании Vosk. Whisper работает напрямую с аудиофайлами без конвертации.

## Установка и настройка

### 1. Создание виртуального окружения

#### Windows (PowerShell):
```powershell
# Создание виртуального окружения
python -m venv venv

# Активация виртуального окружения
.\venv\Scripts\Activate.ps1

# Если возникает ошибка выполнения скриптов, выполните:
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

#### Windows (CMD):
```cmd
# Создание виртуального окружения
python -m venv venv

# Активация виртуального окружения
venv\Scripts\activate.bat
```

#### Linux/macOS:
```bash
# Создание виртуального окружения
python3 -m venv venv

# Активация виртуального окружения
source venv/bin/activate
```

### 2. Установка Python-зависимостей

После активации виртуального окружения:

```bash
pip install -r requirements.txt
```

Это установит:
- `vosk` - библиотека для распознавания речи (движок Vosk)
- `faster-whisper` - библиотека для распознавания речи (движок Whisper)

**⚠️ Внимание для Python 3.13+:**
Если вы используете Python 3.13 или новее, установка `faster-whisper` может требовать Rust. В этом случае рекомендуется:
1. Установить Rust (https://rustup.rs/) и затем установить `faster-whisper`
2. Или использовать Python 3.11-3.12 для лучшей совместимости
3. Или использовать Vosk вместо Whisper

### 3. Установка ffmpeg (только для Vosk)

**Примечание:** Если планируете использовать только Whisper, этот шаг можно пропустить.

**Самый простой способ (рекомендуется):**

#### Windows:
```powershell
# С помощью Chocolatey (https://chocolatey.org/)
choco install ffmpeg

# ИЛИ с помощью Scoop (https://scoop.sh/)
scoop install ffmpeg

# ИЛИ через winget (встроен в Windows 10/11)
winget install ffmpeg
```

#### Linux (Ubuntu/Debian):
```bash
sudo apt update && sudo apt install ffmpeg
```

#### macOS:
```bash
brew install ffmpeg
```

**Проверка установки:**
```bash
ffmpeg -version
```

**Примечание:** Если `ffmpeg` не установлен, программа выведет подробные инструкции по установке при первом запуске.

### 4. Загрузка модели (только для Vosk)

1. Перейдите на страницу моделей: https://alphacephei.com/vosk/models
2. Скачайте нужную модель для вашего языка:
   - **Для русского языка:**
     - `vosk-model-small-ru-0.22` (~45 MB) - быстрая, хорошая точность
     - `vosk-model-ru-0.42` (~1.5 GB) - большая, максимальная точность
3. Распакуйте архив в папку `models/`

Например, для русского языка:
```
models/
  └── vosk-model-small-ru-0.22/
      ├── am/
      ├── conf/
      ├── graph/
      └── ivector/
```

### 5. Настройка конфигурации

Отредактируйте файл `config.json` и выберите движок распознавания:

**Вариант А: Использование Vosk (быстрый)**

```json
{
  "engine": "vosk",
  "vosk_model_path": "models/vosk-model-small-ru-0.22",
  "input_dir": ".data/input",
  "output_dir": ".data/output",
  "processed_dir": ".data/processed",
  "temp_dir": ".data/temp",
  "sample_rate": 16000,
  "supported_formats": [".wav", ".mp3", ".ogg", ".flac", ".m4a", ".wma", ".aac", ".webm"]
}
```

**Вариант Б: Использование Whisper (точный, рекомендуется)**

```json
{
  "engine": "whisper",
  "whisper_model": "base",
  "whisper_device": "cpu",
  "input_dir": ".data/input",
  "output_dir": ".data/output",
  "processed_dir": ".data/processed",
  "temp_dir": ".data/temp",
  "sample_rate": 16000,
  "supported_formats": [".wav", ".mp3", ".ogg", ".flac", ".m4a", ".wma", ".aac", ".webm"]
}
```

**Размеры моделей Whisper:**
- `tiny` - ~75 MB (быстрая, средняя точность)
- `base` - ~140 MB (оптимальное соотношение скорость/качество) ⭐ **Рекомендуется**
- `small` - ~460 MB (хорошая точность)
- `medium` - ~1.5 GB (очень хорошая точность)
- `large` - ~3 GB (максимальная точность, требует GPU)

**Опционально: явное указание языка (только для нестандартных моделей):**

Если используете модель с нестандартным названием, можете явно указать `language`:

```json
{
  "language": "ru",
  "model_path": "models/my-custom-model",
  "input_dir": ".data/input",
  "output_dir": ".data/output",
  "processed_dir": ".data/processed",
  "sample_rate": 16000,
  "supported_formats": [".wav", ".mp3", ".ogg", ".flac", ".m4a", ".wma", ".aac", ".webm"]
}
```

**Общие параметры:**
- `engine` - движок распознавания: `"vosk"` или `"whisper"`
- `input_dir` - директория с входными аудиофайлами
- `output_dir` - директория для сохранения результатов транскрипции
- `processed_dir` - директория для обработанных аудиофайлов
- `temp_dir` - директория для временных файлов (WAV конвертации, автоматически удаляются)
- `sample_rate` - частота дискретизации (16000 Hz)
- `supported_formats` - список поддерживаемых форматов

**Параметры для Vosk:**
- `vosk_model_path` - путь к распакованной модели Vosk
- `language` - **[опционально]** язык определяется автоматически из названия модели

**Параметры для Whisper:**
- `whisper_model` - размер модели: `tiny`, `base`, `small`, `medium`, `large`
- `whisper_device` - **[опционально]** устройство: `cpu` (по умолчанию) или `cuda` (для GPU)
- `language` - **[опционально]** Whisper определяет язык автоматически

## Сравнение движков

| Характеристика | Vosk | Whisper |
|----------------|------|---------|
| **Качество** | Хорошее | Отличное ⭐ |
| **Скорость** | Быстрая ⚡ | Средняя |
| **Требует ffmpeg** | ✅ Да | ❌ Нет |
| **Требует скачивание** | ✅ Да (вручную) | ❌ Нет (автоматически) |
| **Работа с шумом** | Средняя | Отличная |
| **Определение языка** | Из названия модели | Автоматически |
| **Поддержка языков** | ~20 | ~100 |
| **Рекомендуется для** | Скорости | Качества |

## Использование

### 1. Подготовка файлов

Поместите аудиофайлы для обработки в папку `.data/input/`:

```
.data/
  └── input/
      ├── audio1.mp3
      ├── audio2.wav
      └── recording.m4a
```

### 2. Запуск программы

Убедитесь, что виртуальное окружение активировано, затем запустите:

```bash
python speech_recognition.py
```

### 3. Результаты

Результаты транскрибации будут сохранены в папке `.data/output/` в формате Markdown:

```
.data/
  ├── input/          # Новые файлы для обработки
  ├── output/         # Результаты транскрибации
  │   ├── audio1.md
  │   ├── audio2.md
  │   └── recording.md
  └── processed/      # Обработанные аудиофайлы
      ├── audio1.mp3
      ├── audio2.wav
      └── recording.m4a
```

**Каждый файл `.md` содержит:**
- Название исходного файла
- Дату и время обработки
- Язык распознавания
- Полный текст транскрипции

**Обработанные аудиофайлы** автоматически перемещаются из `input/` в `processed/` для удобства организации.

### Пример вывода программы

```
============================================================
Программа транскрибации аудиофайлов (Vosk)
============================================================
Загрузка модели из models/vosk-model-ru-0.10...
Модель успешно загружена!
Обнаружен язык модели: ru
✓ Язык не указан в конфигурации, используется автоопределенный: ru

Найдено файлов для обработки: 3

============================================================
Обработка файла: audio1.mp3
============================================================
Конвертация .mp3 -> WAV...
Транскрибация аудио...
✓ Транскрипция сохранена: .data/output/audio1.md
✓ Файл перемещен в: .data/processed/audio1.mp3

============================================================
Обработка завершена!
Успешно обработано: 3 из 3
============================================================
```

### Автоопределение языка

Программа автоматически определяет язык из названия модели. **Параметр `language` указывать не нужно:**

```json
{
  "model_path": "models/vosk-model-small-ru-0.22"
}
```

**Вывод программы:**
```
Обнаружен язык модели: ru
✓ Язык не указан в конфигурации, используется автоопределенный: ru
```

Программа поддерживает все стандартные форматы названий моделей Vosk.

### Валидация соответствия языка и модели

Программа автоматически проверяет соответствие языка в конфигурации и названия модели.

**Если языки не совпадают, программа автоматически исправит это:**

```
============================================================
Программа транскрибации аудиофайлов (Vosk)
============================================================
Загрузка модели из models/vosk-model-small-ru-0.22...
Модель успешно загружена!
Обнаружен язык модели: ru

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
⚠️  ВНИМАНИЕ: Обнаружено несоответствие!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Язык в конфигурации: 'en'
Язык модели: 'ru'

Распознавание будет выполняться на языке: ru
(определяется моделью, а не параметром 'language' в config.json)

💡 Рекомендация: обновите параметр 'language' в config.json
   на значение 'ru' для корректной документации.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

🔧 Автоматическое исправление: используется 'ru' для выходных файлов
```

**Важно:** Реальный язык распознавания **всегда определяется моделью**, а не параметром `language` в конфигурации. Программа автоматически использует правильный язык для выходных файлов, даже если в конфигурации указан неверный.

## Структура проекта

```
speech-recognition/
├── .data/
│   ├── input/          # Входные аудиофайлы (сюда помещаете файлы для обработки)
│   │   └── .gitkeep
│   ├── output/         # Результаты транскрибации в Markdown
│   │   └── .gitkeep
│   ├── processed/      # Обработанные аудиофайлы (автоматически перемещаются сюда)
│   │   └── .gitkeep
│   └── temp/           # Временные файлы (WAV конвертации, автоматически удаляются)
│       └── .gitkeep
├── models/             # Модели Vosk
│   └── .gitkeep
├── venv/               # Виртуальное окружение (создается при установке)
├── config.json         # Конфигурационный файл
├── speech_recognition.py  # Основной скрипт
├── requirements.txt    # Зависимости Python
├── .gitignore         # Исключения для Git
├── CHANGELOG.md       # История изменений
└── README.md          # Этот файл
```

## Устранение неполадок

### Ошибка: "ffmpeg не найден" или ошибка конвертации

**Причина:** `ffmpeg` не установлен в системе или не доступен в PATH.

**Решение:** 
1. Установите ffmpeg (см. [инструкцию выше](#3-установка-ffmpeg))
2. Проверьте установку:
   ```bash
   ffmpeg -version
   ```
3. Если ffmpeg установлен, но ошибка остаётся - перезапустите терминал/командную строку

**Примечание:** Программа автоматически покажет подробные инструкции по установке при возникновении этой ошибки.

### Ошибка: "Модель не найдена"

**Решение:** 
1. Проверьте, что модель скачана и распакована в папку `models/`
2. Убедитесь, что путь в `config.json` соответствует имени папки модели

### Предупреждение о несоответствии языка и модели

**Проблема:** При запуске программа показывает предупреждение о несовпадении языка в конфигурации и языка модели.

**Решение:** 
1. Откройте файл `config.json`
2. Измените параметр `language` на значение, соответствующее модели
3. Например, если используется модель `vosk-model-small-ru-0.22`, установите `"language": "ru"`

**Примечание:** Это предупреждение не критично - распознавание продолжит работать, но в выходных файлах будет указан неверный язык. Программа автоматически определяет язык из названия модели.

### Низкое качество распознавания

**Решение:**
1. **Используйте правильную языковую модель** - убедитесь, что модель соответствует языку аудио
2. Используйте более крупную модель (например, `vosk-model-ru-0.42` вместо `vosk-model-small-ru-0.22`)
3. Улучшите качество исходного аудио (уменьшите шум, увеличьте громкость)

### Ошибка активации виртуального окружения в Windows PowerShell

**Решение:** Разрешите выполнение скриптов:
```powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

## Поддерживаемые языки

Vosk поддерживает множество языков. Полный список моделей доступен на [странице моделей](https://alphacephei.com/vosk/models):

- Русский (ru)
- Английский (en)
- Немецкий (de)
- Французский (fr)
- Испанский (es)
- Китайский (cn)
- И многие другие...

## Лицензия

Этот проект использует библиотеку Vosk, которая распространяется под лицензией Apache 2.0.

## Дополнительная информация

- [История изменений](CHANGELOG.md) - что нового в версии 2.1
- [Документация Vosk](https://alphacephei.com/vosk/)
- [Vosk на GitHub](https://github.com/alphacep/vosk-api)
- [Модели для разных языков](https://alphacephei.com/vosk/models)

## Автор

Разработано с использованием Python и Vosk API.
